{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448d26fc",
   "metadata": {},
   "source": [
    "This notebook shows how to do inference with yolonas and pretrained weights using the gpu. \n",
    "\n",
    "To add kernel I managed to add path to where venvs are stored, this solved the issue. \n",
    "\n",
    "LÃ¤nk till YOLO NAS 2025\n",
    "https://www.labellerr.com/blog/ultimate-yolo-nas-guide/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8255551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to install these packages in the venv, don' know if this can be done in the notebook or must be done in the terminal\n",
    "#!pip install ultralytics super_gradients opencv-python\n",
    "\n",
    "\n",
    "# Important Note: \n",
    "#   * Use python<=3.11 as above python version donot support super_gradients\n",
    "#   * onnx may be needed to reinstall with the correct versions needed by ultralytics, for me it solved the issue with importing onnxruntime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeca450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13700b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"2sj781jgq3jIhtK8shSJ\")\n",
    "project = rf.workspace(\"abbrock-bolt-detection\").project(\"yolo-detection-final-training\")\n",
    "version = project.version(6)\n",
    "dataset = version.download(\"darknet\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a47e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpu or cpu device\n",
    "import torch\n",
    "import os\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Device: \", DEVICE)\n",
    "\n",
    "MODEL_ARCH = \"yolo_nas_m\" \n",
    "\n",
    "# you can increase this number depending on your GPU, more batch size means faster training\n",
    "BATCH_SIZE = 8 \n",
    "# Epoch Number\n",
    "MAX_EPOCHS = 300\n",
    "\n",
    "# base directory\n",
    "HOME=os.getcwd()\n",
    "print(\"Home dir: \", HOME)\n",
    "EXPERIMENT_NAME=\"detect_bolts_test_final_det_v6-1\"\n",
    "CHECKPOINT_DIR = \"/import/bulkhome/c21ion/exjobb/yolonas_test_setup/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca95617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "print(\"sys.executable:\", sys.executable)\n",
    "print(\"python:\", sys.version.splitlines()[0])\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "try:\n",
    "    import onnxruntime as ort, inspect, sys\n",
    "    print(\"module file:\", getattr(ort, \"__file__\", None))\n",
    "    print(\"version:\", getattr(ort, \"__version__\", None))\n",
    "    import onnxruntime.capi.onnxruntime_validation as v\n",
    "    print(\"validation attrs:\", [a for a in dir(v) if \"package\" in a.lower() or \"version\" in a.lower()])\n",
    "except Exception as e:\n",
    "    print(\"validation import error:\", type(e).__name__, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb707fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training import Trainer\n",
    "\n",
    "trainer = Trainer(experiment_name=EXPERIMENT_NAME, ckpt_root_dir=CHECKPOINT_DIR)\n",
    "\n",
    "# Dataset , Label information\n",
    "dataset_params = {\n",
    "    'data_dir': HOME + '/YOLO-detection-final-training-6-yolov8', # path to dataset \n",
    "    'train_images_dir':'train/images',\n",
    "    'train_labels_dir':'train/labels',\n",
    "    'val_images_dir':'valid/images',\n",
    "    'val_labels_dir':'valid/labels',\n",
    "    'classes': ['Rockbolts'] # labels here \n",
    "}\n",
    "print(\"Dataset params: \", dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f75469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training.dataloaders.dataloaders import (\n",
    "    coco_detection_yolo_format_train, coco_detection_yolo_format_val)\n",
    "\n",
    "train_data = coco_detection_yolo_format_train(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['train_images_dir'],\n",
    "        'labels_dir': dataset_params['train_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'num_workers': 2\n",
    "    }\n",
    ")\n",
    "\n",
    "val_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['val_images_dir'],\n",
    "        'labels_dir': dataset_params['val_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'num_workers': 2\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abeae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inference\n",
    "model = inference.load_roboflow_model(\"yolo-nas-l-640\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training import models\n",
    "\n",
    "model = models.get(\n",
    "    MODEL_ARCH,  # yolo_nas_m\n",
    "    num_classes=len(dataset_params['classes']),\n",
    "    #num_classes=None,\n",
    "    pretrained_weights=\"coco\", # TODO: Must remember to use weights with valid licence\n",
    "    #checkpoint_path=\"/import/bulkhome/c21ion/exjobb/yolonas_test_setup/checkpoints/detect_bolts_test_1/RUN_20251020_082229_796307/ckpt_latest.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training params. \n",
    "# Demonstration says that 'mixed_precision' may be set to true, \n",
    "# but demo had problems due to its gpu\n",
    "from super_gradients.training.losses import PPYoloELoss\n",
    "from super_gradients.training.metrics import DetectionMetrics_050\n",
    "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
    "\n",
    "train_params = {\n",
    "    'silent_mode': False,\n",
    "    \"average_best_models\":True,\n",
    "    \"warmup_mode\": \"linear_epoch_step\",\n",
    "    \"warmup_initial_lr\": 1e-6,\n",
    "    \"lr_warmup_epochs\": 3,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_mode\": \"cosine\",\n",
    "    \"cosine_final_lr_ratio\": 0.1,\n",
    "\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
    "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
    "    \"ema\": True,\n",
    "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
    "    \"max_epochs\": MAX_EPOCHS,\n",
    "    \"mixed_precision\":  False , # TRUE BY DEFAULT , depending to GPU setting this to True might cause nan value problem in metrics\n",
    "    \"loss\": PPYoloELoss(\n",
    "        use_static_assigner=False,\n",
    "        num_classes=len(dataset_params['classes']),\n",
    "        reg_max=16\n",
    "    ),\n",
    "    \"valid_metrics_list\": [\n",
    "        DetectionMetrics_050(\n",
    "            score_thres=0.1,\n",
    "            top_k_predictions=300, # Should be lowered to 5-10\n",
    "            num_cls=len(dataset_params['classes']),\n",
    "            normalize_targets=True,\n",
    "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
    "                score_threshold=0.01,\n",
    "                nms_top_k=1000, # Should be lowered to 50-100\n",
    "                max_predictions=300, # Should be lowered to around 5\n",
    "                nms_threshold=0.7\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    \"metric_to_watch\": 'mAP@0.50'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "import numpy\n",
    "\n",
    "torch.serialization.add_safe_globals([\n",
    "    numpy._core.multiarray._reconstruct, \n",
    "    numpy.ndarray, \n",
    "    numpy.dtype,\n",
    "    numpy.dtypes.Float64DType\n",
    "])\n",
    "\n",
    "trainer.train(\n",
    "    model=model,\n",
    "    training_params=train_params,\n",
    "    train_loader=train_data,\n",
    "    valid_loader=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4be047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model from training\n",
    "from super_gradients.training import models\n",
    "\n",
    "inference_model = models.get(\n",
    "    MODEL_ARCH,\n",
    "    num_classes=len(dataset_params['classes']),\n",
    "    checkpoint_path=\"/import/bulkhome/c21ion/exjobb/yolonas_test_setup/checkpoints/detect_bolts_test_1/RUN_20251020_102530_541823/ckpt_best.pth\" # Select model\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9231ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get base model only without training head etc.\n",
    "inference_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b1611",
   "metadata": {},
   "source": [
    "Select if prediction or sample from training data should be presented by running either of the following two sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify training data\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Output lists ---\n",
    "NUM_TO_PRINT = 20\n",
    "images_to_show = [] # format (image, (bboxes, confidences, labels))\n",
    "# --- END Output lists---\n",
    "\n",
    "val_data_label_path = os.path.join(dataset_params['data_dir'] ,dataset_params['val_labels_dir'])\n",
    "val_data_image_path =  os.path.join(dataset_params['data_dir'] ,dataset_params['val_images_dir'])\n",
    "\n",
    "folder_labels = os.listdir(val_data_label_path)\n",
    "\n",
    "for _ in range(NUM_TO_PRINT):  # Show 5 random images, always assume there is only one bbox per image\n",
    "    lines = []\n",
    "    while len(lines) == 0:\n",
    "        random_index = np.random.randint(0, len(folder_labels))\n",
    "\n",
    "        label_name = folder_labels[random_index]\n",
    "        image_name = label_name.split(\".txt\")[0] + \".jpg\"\n",
    "        print(f\"Selected image: {image_name} with index {random_index}\")\n",
    "\n",
    "        image_path = os.path.join(val_data_image_path, image_name)\n",
    "        label_path = os.path.join(val_data_label_path, label_name)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = [l.strip() for l in f if l.strip()]\n",
    "\n",
    "\n",
    "    line = lines[0]\n",
    "    toks = line.split()\n",
    "    print(\"Label line: \", line)\n",
    "    if len(toks) < 5:\n",
    "        print(\"Invalid label line: \", line)\n",
    "    cls_id = toks[0]\n",
    "    try:\n",
    "        x_c = float(toks[1]); y_c = float(toks[2])\n",
    "        bw = float(toks[3]); bh = float(toks[4])\n",
    "    except ValueError:\n",
    "        print(\"Invalid label line: \", line)\n",
    "    print(f\"Tokens: {toks}\")\n",
    "\n",
    "    x1 = int((x_c - bw/2) * 640)\n",
    "    y1 = int((y_c - bh/2) * 640)\n",
    "    x2 = int((x_c + bw/2) * 640)\n",
    "    y2 = int((y_c + bh/2) * 640)    \n",
    "\n",
    "    bbox = (x1, y1, x2, y2)\n",
    "    confidence = 1.0\n",
    "    label = int(cls_id)\n",
    "\n",
    "    # Package in lists to comply with model.predict output\n",
    "    images_to_show.append(((image, image_name), ([bbox], [confidence], [label])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d38659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Perform prediction and prepare for display ---\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Output\n",
    "NUM_TO_PRINT = 5\n",
    "images_to_show = [] # format (image, (bboxes, confidences, labels))\n",
    "\n",
    "# Verify model prediction by taking random image from validation set\n",
    "val_data_label_path = os.path.join(dataset_params['data_dir'] ,dataset_params['val_labels_dir'])\n",
    "val_data_image_path =  os.path.join(dataset_params['data_dir'] ,dataset_params['val_images_dir'])\n",
    "\n",
    "folder_labels = os.listdir(val_data_label_path)\n",
    "\n",
    "for _ in range(NUM_TO_PRINT):  # Show 5 random images\n",
    "    random_index = np.random.randint(0, len(folder_labels))\n",
    "\n",
    "    label_name = folder_labels[random_index]\n",
    "    image_name = label_name.split(\".txt\")[0] + \".jpg\"\n",
    "    print(f\"Selected image: {image_name} with index {random_index}\")\n",
    "\n",
    "    image_path = os.path.join(val_data_image_path, image_name)\n",
    "    label_path = os.path.join(val_data_label_path, label_name)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # --- predict ---\n",
    "    model_result = inference_model.predict(image, conf=0.35)\n",
    "\n",
    "    print(model_result.prediction)\n",
    "\n",
    "    # Bounding boxes, labels, confidence, and label dictionary\n",
    "    bboxes = model_result.prediction.bboxes_xyxy\n",
    "    print(\"Bboxes: \", bboxes)\n",
    "    confidences = model_result.prediction.confidence\n",
    "    labels = model_result.prediction.labels\n",
    "\n",
    "    images_to_show.append(((image, image_name), (bboxes, confidences, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb366170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes and labels on the image\n",
    "label_dict={0:\"Rockbolts\"}\n",
    "\n",
    "for (image, image_name), (bboxes, confidences, labels) in images_to_show:\n",
    "\n",
    "    for i in range(len(bboxes)):\n",
    "        bbox = bboxes[i]\n",
    "        confidence = confidences[i]\n",
    "        label = labels[i]\n",
    "        print(f\"Box: {bbox}, Confidence: {confidence}, Label: {label}\")\n",
    "        \n",
    "        # Coordinates of the bounding box\n",
    "        x1, y1, x2, y2 = [int(coord) for coord in bbox]\n",
    "        \n",
    "\n",
    "        # Draw the rectangle\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        cv2.putText(image, image_name, (50,50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    fontScale=0.5, color=(255, 255, 255), thickness=1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        # Create label text with confidence\n",
    "        label_text = f\"{label}: {confidence:.2f}\"\n",
    "\n",
    "        # Put the label text above the bounding box\n",
    "        cv2.putText(image, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    fontScale=0.5, color=(255, 255, 255), thickness=1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # Convert BGR to RGB for displaying in matplotlib\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evalutate model performance\n",
    "\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_yolonas_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
